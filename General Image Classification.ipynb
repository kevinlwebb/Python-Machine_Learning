{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Image Classification\n",
    "\n",
    "Given a Dataframe with pixel values of images. Each image takes up 144 rows by 120 columns of the DataFrame.\n",
    "The columns are [index, target, img_id, px0,..., px119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pixel Columns for the DataFrame: 120 pixels wide\n",
    "imgCols = ['px0', 'px1', 'px2', 'px3', 'px4', 'px5', 'px6', 'px7', \n",
    "               'px8', 'px9', 'px10', 'px11', 'px12', 'px13', 'px14', 'px15', \n",
    "               'px16', 'px17', 'px18', 'px19', 'px20', 'px21', 'px22', 'px23',\n",
    "               'px24', 'px25', 'px26', 'px27', 'px28', 'px29', 'px30', 'px31', \n",
    "               'px32', 'px33', 'px34', 'px35', 'px36', 'px37', 'px38', 'px39', \n",
    "               'px40', 'px41', 'px42', 'px43', 'px44', 'px45', 'px46', 'px47', \n",
    "               'px48', 'px49', 'px50', 'px51', 'px52', 'px53', 'px54', 'px55', \n",
    "               'px56', 'px57', 'px58', 'px59', 'px60', 'px61', 'px62', 'px63',\n",
    "               'px64', 'px65', 'px66', 'px67', 'px68', 'px69', 'px70', 'px71',\n",
    "               'px72', 'px73', 'px74', 'px75', 'px76', 'px77', 'px78', 'px79',\n",
    "               'px80', 'px81', 'px82', 'px83', 'px84', 'px85', 'px86', 'px87',\n",
    "               'px88', 'px89', 'px90', 'px91', 'px92', 'px93', 'px94', 'px95',\n",
    "               'px96', 'px97', 'px98', 'px99', 'px100', 'px101', 'px102', 'px103',\n",
    "               'px104', 'px105', 'px106', 'px107', 'px108', 'px109', 'px110', 'px111',\n",
    "               'px112', 'px113', 'px114', 'px115', 'px116', 'px117', 'px118', 'px119']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img: numpy.array tuple from matplotlib.image.imread()\n",
    "def Convert_Image_DF(img):\n",
    "    aHigh = []\n",
    "    aWidth = []\n",
    "    \n",
    "    for High in img:\n",
    "        aWidth = []         \n",
    "        \n",
    "        for Width in High:\n",
    "            RGB = \"|\".join(map(str, Width))        \n",
    "            aWidth.append(RGB)\n",
    "\n",
    "        aHigh.append(aWidth)\n",
    "        \n",
    "    return pd.DataFrame(data=aHigh, columns=imgCols)\n",
    "\n",
    "def Convert_DF_Image(df):\n",
    "    arr_row = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        arr_col = []\n",
    "\n",
    "        for col in row:\n",
    "            arr_split = col.split(\"|\")\n",
    "            \n",
    "            # In this particular case, the pixel tuple that has\n",
    "            # four values is already between the values of\n",
    "            # 0 and 1. No need to divide by 255.\n",
    "            if len(arr_split) == 4:\n",
    "                row = [np.float32(item) for item in arr_split]\n",
    "                # Remove the transparency value in order to match\n",
    "                # with the 3 value tuple\n",
    "                row.pop()\n",
    "                arr_col.append(row)\n",
    "                \n",
    "            else:\n",
    "                row = [int(item)/255 for item in arr_split]\n",
    "                arr_col.append(row)\n",
    "            \n",
    "        arr_row.append(arr_col)\n",
    "\n",
    "    return arr_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training frame\n",
    "train_data = pd.read_csv(training_path, index_col = \"index\")\n",
    "\n",
    "# Unique Image Ids and Target Values\n",
    "df = train_data[[\"target\", \"img_id\"]].drop_duplicates()\n",
    "\n",
    "# Separate target from predictors\n",
    "y=[train_data.loc[train_data.img_id == i].target.mean() for i in train_data.img_id.unique()]\n",
    "y = to_categorical(y)\n",
    "\n",
    "train_image = []\n",
    "\n",
    "for i in train_data.img_id.unique():\n",
    "    IMAGE_ID = i\n",
    "\n",
    "    df = train_data.loc[train_data.img_id == IMAGE_ID]\n",
    "\n",
    "    # Only care about the encoded image data portion of the dataframe\n",
    "    df = df[imgCols]\n",
    "\n",
    "    img = Convert_DF_Image(df)\n",
    "    train_image.append(img)\n",
    "\n",
    "X = np.array(train_image)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Add Layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(144, 120, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Last Dense must match up with the amount of unique targets you have\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing data\n",
    "test_data = pd.read_csv(testing_path, index_col = \"index\")\n",
    "\n",
    "test_image = []\n",
    "\n",
    "for i in test_data.img_id.unique():\n",
    "    IMAGE_ID = i\n",
    "\n",
    "    df = test_data.loc[test_data.img_id == IMAGE_ID]\n",
    "\n",
    "    # Only care about the encoded image data portion of the dataframe\n",
    "    df = df[imgCols]\n",
    "\n",
    "    img = Convert_DF_Image(df)\n",
    "    test_image.append(img)\n",
    "\n",
    "final_test_X = np.array(test_image)\n",
    "\n",
    "# Create predictions from testing data and write them to predictions_path\n",
    "predictions = model.predict_classes(final_test_X)\n",
    "\n",
    "# Disperse the predictions along the original Dataframe\n",
    "for num,i in enumerate(test_data.img_id.unique()):\n",
    "    test_data.loc[test_data.img_id == i, \"target\"] = predictions[num]\n",
    "    print(\"Num: \", predictions[num])\n",
    "    print(test_data.loc[test_data.img_id == i, \"target\"])\n",
    "\n",
    "predict_frame = pd.DataFrame(test_data.target, columns=[\"target\"], index = test_data.index)\n",
    "predict_frame.to_csv(predictions_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
